#+TITLE: Understanding Autoware NDT Scan Matching
#+AUTHOR: CUDA NDT Matcher Project
#+DATE: 2026-01-19
#+SETUPFILE: github.theme

#+begin_NOTE
*Dataflow Diagrams*: See =docs/diagrams/ndt-dataflow.typ= for Typst-based visual diagrams of the NDT algorithm, CPU/GPU pipelines, and memory layout. Compile with: =typst compile docs/diagrams/ndt-dataflow.typ=
#+end_NOTE

* Introduction

This tutorial explains how Autoware's NDT (Normal Distributions Transform) scan matcher works. NDT is a probabilistic point cloud registration algorithm used for localization in autonomous driving.

The Autoware implementation is based on *Magnusson's 2009 PhD thesis*: "The Three-Dimensional Normal-Distributions Transform -- an Efficient Representation for Registration, Surface Analysis, and Loop Detection."

** What Does NDT Do?

NDT estimates the vehicle's pose (position + orientation) by matching a LiDAR scan against a pre-built 3D point cloud map. Given:

- *Map*: A 3D point cloud of the environment (stored as a voxel grid)
- *Scan*: Current LiDAR point cloud from the vehicle's sensors
- *Initial guess*: Approximate pose from odometry/IMU

NDT finds the optimal transformation that best aligns the scan to the map.

** Why NDT Over ICP?

| Feature        | ICP (Iterative Closest Point) | NDT                              |
|----------------+-------------------------------+----------------------------------|
| Representation | Raw points                    | Gaussian distributions per voxel |
| Smoothness     | Discrete, non-differentiable  | Smooth, differentiable score     |
| Speed          | O(N log M) per iteration      | O(N) per iteration               |
| Robustness     | Sensitive to outliers         | Inherently robust                |

NDT models the map as a collection of Gaussian distributions, providing a smooth cost function suitable for Newton optimization.

* Algorithm Overview

#+begin_src mermaid
flowchart TD
    A[Input: Scan + Initial Guess] --> B[Transform Scan Points]
    B --> C[Find Nearby Voxels]
    C --> D[Compute Score, Gradient, Hessian]
    D --> E[Newton Step: delta = -H^-1 * g]
    E --> F[Line Search]
    F --> G{Converged?}
    G -->|No| B
    G -->|Yes| H[Output: Final Pose]
#+end_src

The algorithm iterates until convergence:
1. Transform source points using current pose estimate
2. For each transformed point, find nearby voxels in the map
3. Compute the NDT score (negative log-likelihood) and its derivatives
4. Solve Newton step to get pose update direction
5. Apply line search to find optimal step length
6. Update pose and check convergence

* Voxel Grid Construction

The map is preprocessed into a voxel grid where each voxel stores a Gaussian distribution.

** Voxel Structure

Each voxel contains:

| Field        | Type      | Description                      |
|--------------+-----------+----------------------------------|
| =mean_=      | Vector3   | Centroid of points in voxel      |
| =cov_=       | Matrix3x3 | Covariance matrix                |
| =icov_=      | Matrix3x3 | Inverse covariance (precomputed) |
| =nr_points_= | int       | Number of points in voxel        |

** Building the Voxel Grid

#+begin_src cpp
// Pseudocode for voxel grid construction
void build_voxel_grid(PointCloud& map, float resolution) {
    // 1. Assign points to voxels
    for (auto& point : map) {
        int voxel_id = floor(point / resolution);
        voxels[voxel_id].points.push_back(point);
    }

    // 2. Compute statistics for each voxel
    for (auto& [id, voxel] : voxels) {
        if (voxel.points.size() < min_points_per_voxel)
            continue;  // Skip sparse voxels

        // Compute mean
        voxel.mean = sum(voxel.points) / voxel.points.size();

        // Compute covariance
        for (auto& p : voxel.points) {
            Vector3 d = p - voxel.mean;
            voxel.cov += d * d.transpose();
        }
        voxel.cov /= (voxel.points.size() - 1);

        // Regularize and invert covariance
        regularize(voxel.cov);  // Ensure positive definite
        voxel.icov = voxel.cov.inverse();
    }

    // 3. Build KD-tree on voxel centroids for fast lookup
    kdtree.build(voxel_centroids);
}
#+end_src

** Covariance Regularization

To ensure numerical stability, eigenvalue decomposition is used:

$$\Sigma = V \Lambda V^T$$

Small eigenvalues are clamped: $\lambda_i = \max(\lambda_i, 0.01 \cdot \lambda_{max})$

This prevents singular covariance matrices while preserving the principal directions.

#+begin_NOTE
*Performance Impact*: Voxel grid construction is expensive but done only once per map load. The KD-tree enables fast $O(\log V)$ voxel lookup during alignment.
#+end_NOTE

* NDT Score Function

The NDT score measures how well the scan aligns with the map. It's based on the probability of a point belonging to a voxel's Gaussian distribution.

** Probability Density

For a point $\mathbf{x}$ and voxel with mean $\boldsymbol{\mu}$ and covariance $\Sigma$:

$$p(\mathbf{x}) = -d_1 \cdot \exp\left(-\frac{d_2}{2} (\mathbf{x} - \boldsymbol{\mu})^T \Sigma^{-1} (\mathbf{x} - \boldsymbol{\mu})\right)$$

Where:
- $d_1, d_2$ are constants derived from the outlier ratio (typically 0.55)
- The negative sign makes this a cost to minimize

** Gaussian Fitting Constants

The constants $d_1$, $d_2$, $d_3$ are computed from the outlier ratio $p$:

#+begin_src cpp
// From multigrid_ndt_omp_impl.hpp lines 236-243
double p = outlier_ratio_;  // typically 0.55
gauss_d1_ = -log(p);
gauss_d2_ = -2 * log((-log(p * gauss_c2_)) / (-log(p)));
gauss_d3_ = gauss_d1_ + gauss_d2_ / 2.0;
#+end_src

These constants control the shape of the score function:
- Higher $d_1$ increases penalty for misalignment
- Higher $d_2$ sharpens the Gaussian peak

** Total Score

The total score is the sum over all source points and their nearby voxels:

$$S = \sum_{i=1}^{N} \sum_{j \in \text{nearby}(i)} p(\mathbf{T}(\mathbf{x}_i))$$

Where $\mathbf{T}$ is the current transformation and nearby($i$) returns voxels within search radius.

* Transformation Representation

Autoware uses a 6-parameter pose representation:

$$\mathbf{p} = [x, y, z, \text{roll}, \text{pitch}, \text{yaw}]^T$$

** Transformation Matrix

The pose is converted to a 4x4 homogeneous transformation matrix:

$$\mathbf{T} = \begin{bmatrix} \mathbf{R} & \mathbf{t} \\ \mathbf{0} & 1 \end{bmatrix}$$

Where $\mathbf{R}$ is the rotation matrix (X-Y-Z Euler angles) and $\mathbf{t}$ is the translation.

** Euler Angle Convention

Autoware uses X-Y-Z extrinsic rotation order:

$$\mathbf{R} = \mathbf{R}_z(\text{yaw}) \cdot \mathbf{R}_y(\text{pitch}) \cdot \mathbf{R}_x(\text{roll})$$

#+begin_src cpp
// Rotation matrix construction
Eigen::Matrix4d pose_to_matrix(const Vector6& p) {
    double cx = cos(p[3]), sx = sin(p[3]);  // roll
    double cy = cos(p[4]), sy = sin(p[4]);  // pitch
    double cz = cos(p[5]), sz = sin(p[5]);  // yaw

    Matrix4d T = Matrix4d::Identity();
    T(0,0) = cy*cz;
    T(0,1) = cz*sx*sy - cx*sz;
    T(0,2) = sx*sz + cx*cz*sy;
    T(1,0) = cy*sz;
    T(1,1) = cx*cz + sx*sy*sz;
    T(1,2) = cx*sy*sz - cz*sx;
    T(2,0) = -sy;
    T(2,1) = cy*sx;
    T(2,2) = cx*cy;
    T.block<3,1>(0,3) = p.head<3>();  // translation
    return T;
}
#+end_src

* Derivative Computation

The Newton optimization requires the gradient (6x1) and Hessian (6x6) of the score function.

** Angular Derivatives (Precomputed)

To avoid redundant computation, angular derivatives are precomputed once per iteration:

#+begin_src cpp
// From computeAngleDerivatives() - lines 576-650
void computeAngleDerivatives(const Vector6& p) {
    double cx = cos(p[3]), sx = sin(p[3]);
    double cy = cos(p[4]), sy = sin(p[4]);
    double cz = cos(p[5]), sz = sin(p[5]);

    // Jacobian terms (8 entries) - dR/d(roll,pitch,yaw)
    j_ang_(0,0) = -sx*sz + cx*cz*sy;    // d/droll of R[0,2]
    j_ang_(0,1) = -cx*sz - cz*sx*sy;    // d/droll of R[0,1]
    j_ang_(0,2) = cz*cy;                 // d/dpitch of R[0,0]
    // ... 5 more Jacobian terms

    // Hessian terms (15 entries) - d²R/d(pose)²
    h_ang_(0,0) = -cx*sz - cz*sx*sy;    // a2
    h_ang_(0,1) = -cz*sx - cx*sy*sz;    // a3
    h_ang_(0,2) = sx*sy*sz - cx*cz;     // b2
    // ... 12 more Hessian terms
}
#+end_src

These precomputed terms are reused for all points, avoiding $O(N)$ trigonometric evaluations.

** Per-Point Gradient

For each point $\mathbf{x}_i$ in voxel with mean $\boldsymbol{\mu}$ and inverse covariance $\Sigma^{-1}$:

$$\frac{\partial S}{\partial \mathbf{p}} = \sum_i d_1 d_2 \cdot e_i \cdot (\mathbf{x}_i - \boldsymbol{\mu})^T \Sigma^{-1} \frac{\partial \mathbf{x}_i}{\partial \mathbf{p}}$$

Where:
- $e_i = \exp\left(-\frac{d_2}{2}(\mathbf{x}_i - \boldsymbol{\mu})^T \Sigma^{-1} (\mathbf{x}_i - \boldsymbol{\mu})\right)$
- $\frac{\partial \mathbf{x}_i}{\partial \mathbf{p}}$ is the 3x6 Jacobian of the transformed point

** Per-Point Hessian

The Hessian includes both first and second-order terms:

$$\frac{\partial^2 S}{\partial \mathbf{p}^2} = \sum_i d_1 d_2 \cdot e_i \left[ -d_2 \cdot \mathbf{c}_i \mathbf{c}_i^T + \frac{\partial \mathbf{x}_i}{\partial \mathbf{p}}^T \Sigma^{-1} \frac{\partial \mathbf{x}_i}{\partial \mathbf{p}} + \mathbf{c}_i^T \frac{\partial^2 \mathbf{x}_i}{\partial \mathbf{p}^2} \right]$$

Where $\mathbf{c}_i = \frac{\partial \mathbf{x}_i}{\partial \mathbf{p}}^T \Sigma^{-1} (\mathbf{x}_i - \boldsymbol{\mu})$.

#+begin_NOTE
*Performance Impact*: Derivative computation is the most expensive operation per iteration. It's $O(N \times V)$ where $N$ is point count and $V$ is average voxels per point. Autoware uses OpenMP parallelization with per-thread accumulation.
#+end_NOTE

* Newton Optimization

Once we have the gradient $\mathbf{g}$ and Hessian $\mathbf{H}$, we solve for the Newton step:

$$\Delta \mathbf{p} = -\mathbf{H}^{-1} \mathbf{g}$$

** SVD Solution

Autoware uses SVD for robust inversion:

#+begin_src cpp
// From computeTransformation() lines 315-318
Eigen::JacobiSVD<Eigen::Matrix<double, 6, 6>> sv(
    hessian, Eigen::ComputeFullU | Eigen::ComputeFullV);
delta_p = sv.solve(-score_gradient);
#+end_src

SVD handles near-singular Hessians gracefully, preventing numerical instability.

** Direction Validation

The Newton direction must be a descent direction:

#+begin_src cpp
// Check descent condition
double d_phi_0 = -score_gradient.dot(delta_p);
if (d_phi_0 >= 0) {
    // Not descending, reverse direction
    delta_p *= -1.0;
    d_phi_0 *= -1.0;
}

// Normalize step if too large
double delta_p_norm = delta_p.norm();
if (delta_p_norm > 1.0) {
    delta_p /= delta_p_norm;
}
#+end_src

** Convergence Criteria

The algorithm converges when:

1. *Transformation epsilon*: $\|\Delta \mathbf{p}\| < \epsilon_{trans}$ (default: 0.01)
2. *Max iterations*: Iterations $\geq$ max_iterations (default: 30)

#+begin_src cpp
// Convergence check
nr_iterations_++;
if (nr_iterations_ >= max_iterations_ ||
    delta_p.norm() < transformation_epsilon_) {
    converged_ = true;
}
#+end_src

* Line Search (More-Thuente)

The More-Thuente line search finds an optimal step length $\alpha$ along the Newton direction.

** Why Line Search?

Newton's method can overshoot, especially early in optimization. Line search ensures sufficient decrease in the objective function while maintaining curvature.

** Strong Wolfe Conditions

The line search finds $\alpha$ satisfying:

1. *Armijo (sufficient decrease)*: $f(\mathbf{p} + \alpha \Delta\mathbf{p}) \leq f(\mathbf{p}) + \mu \alpha \nabla f^T \Delta\mathbf{p}$
2. *Curvature*: $|\nabla f(\mathbf{p} + \alpha \Delta\mathbf{p})^T \Delta\mathbf{p}| \leq \nu |\nabla f^T \Delta\mathbf{p}|$

Where $\mu = 10^{-4}$ and $\nu = 0.9$ (typical values).

** Algorithm Sketch

#+begin_src cpp
double computeStepLengthMT(Vector6& p, Vector6& delta_p,
                           double d_phi_0, double phi_0) {
    double alpha = step_size;  // Initial step (default: 0.1)
    double alpha_l = 0, alpha_u = step_max;

    for (int iter = 0; iter < 10; iter++) {
        // Evaluate function at trial step
        Vector6 trial_p = p + alpha * delta_p;
        double phi_a = computeScore(trial_p);
        double d_phi_a = computeDirectionalDerivative(trial_p, delta_p);

        // Check Wolfe conditions
        if (satisfies_armijo(phi_a) && satisfies_curvature(d_phi_a)) {
            return alpha;
        }

        // Update bracket and pick new trial
        updateInterval(alpha_l, alpha_u, alpha, phi_a, d_phi_a);
        alpha = selectTrialValue(alpha_l, alpha_u);
    }
    return alpha;
}
#+end_src

#+begin_WARNING
*Default Disabled*: Autoware disables line search by default (=use_line_search=false=) because the overhead often exceeds the benefit. The fixed step size of 0.1 works well in practice.
#+end_WARNING

** Trial Value Selection

The algorithm uses cubic/quadratic interpolation to pick trial step lengths:

#+begin_src cpp
// From trialValueSelectionMT() - simplified
double selectTrial(double a_l, double a_u, double a_t,
                   double f_l, double f_u, double f_t,
                   double g_l, double g_u, double g_t) {
    // Case 1: f_t > f_l -> Minimum between a_l and a_t
    //         Use cubic interpolation
    // Case 2: g_t * g_l < 0 -> Minimum between a_t and a_u
    //         Sign change indicates minimum exists
    // Case 3: |g_t| <= |g_l| -> Extrapolate beyond a_t
    // Case 4: Otherwise -> Safeguard interpolation
}
#+end_src

* Voxel Search Methods

How we find voxels for each point significantly affects accuracy and speed.

** KDTREE (Recommended)

Uses a KD-tree built on voxel centroids:

#+begin_src cpp
// Radius search for nearby voxels
std::vector<int> nearby;
std::vector<float> distances;
kdtree.radiusSearch(query_point, resolution, nearby, distances);

for (int voxel_idx : nearby) {
    // Accumulate score/gradient/Hessian from this voxel
}
#+end_src

*Complexity*: $O(\log V)$ per point

** DIRECT Methods (Legacy)

Directly compute neighboring voxel indices without KD-tree:

| Method | Description | Voxels Checked |
|--------+-------------+----------------|
| DIRECT1 | Only containing voxel | 1 |
| DIRECT7 | Face-adjacent neighbors | 7 |
| DIRECT26 | All neighbors including diagonals | 27 |

*Not recommended*: DIRECT methods can miss voxels near boundaries and provide less smooth gradients.

#+begin_NOTE
*Performance Impact*: KDTREE is slightly slower per query but provides smoother gradients and better convergence. Autoware defaults to KDTREE.
#+end_NOTE

* Scoring Metrics

Autoware computes two scoring metrics for quality assessment:

** Transform Probability (TP)

Average negative log-likelihood per point:

$$TP = \frac{1}{N} \sum_{i=1}^{N} \max_j\left(-d_1 \exp\left(-\frac{d_2}{2} \|\mathbf{x}_i - \boldsymbol{\mu}_j\|_{\Sigma_j}^2\right)\right)$$

Higher TP indicates better alignment. Typical range: 2.0-5.5.

** Nearest Voxel Transformation Likelihood (NVTL)

Uses only the *highest-scoring voxel* per point:

$$NVTL = \frac{1}{N_{corr}} \sum_{i \in \text{found}} \max_j\left(-d_1 \exp\left(-\frac{d_2}{2} \|\mathbf{x}_i - \boldsymbol{\mu}_j\|_{\Sigma_j}^2\right)\right)$$

NVTL normalizes by found correspondences, making it more robust to partial overlaps.

** Score Thresholds

Autoware uses score thresholds for validation:

#+begin_src cpp
// Reject alignment if score too low
if (nvtl < score_threshold) {
    // Don't publish this pose
    return false;
}
#+end_src

* Map Management

Autoware supports dynamic map loading for large-scale environments.

** Tile-Based Loading

Maps are divided into tiles that are loaded on demand:

#+begin_src cpp
// Check if position is outside current map
if (distance_to_map_center > map_radius - lidar_radius) {
    // Request new map tiles from map server
    requestDifferentialMap(current_position);
}
#+end_src

** Dual-NDT Architecture

To avoid blocking during map updates:

1. *Primary NDT*: Used for active alignment
2. *Secondary NDT*: Built in background with new tiles
3. *Atomic swap*: When secondary is ready, swap pointers

#+begin_src cpp
// Background thread builds new NDT
void mapUpdateThread() {
    while (running) {
        if (map_update_requested) {
            // Build secondary NDT with new tiles
            secondary_ndt_->setInputTarget(new_map);

            // Atomic swap
            std::lock_guard lock(ndt_mutex_);
            std::swap(primary_ndt_, secondary_ndt_);
        }
    }
}
#+end_src

* Performance Considerations

** Critical Path Analysis

| Operation | Time (typical) | Complexity |
|-----------+----------------+------------|
| Point transformation | ~0.1 ms | O(N) |
| Voxel search | ~0.5 ms | O(N log V) |
| Derivative accumulation | ~2.0 ms | O(N * V_avg) |
| Newton solve | ~0.05 ms | O(1) - 6x6 |
| Line search (if enabled) | ~2.0 ms | O(iterations * above) |

*Dominant cost*: Derivative computation, especially the nested loops for gradient/Hessian accumulation.

** OpenMP Parallelization

Autoware uses OpenMP to parallelize the derivative loop:

#+begin_src cpp
#pragma omp parallel for num_threads(threads) schedule(guided, 8) \
    reduction(+:score)
for (int i = 0; i < num_points; i++) {
    // Per-thread gradient/Hessian accumulation
    Eigen::Matrix<double, 6, 1> local_gradient;
    Eigen::Matrix<double, 6, 6> local_hessian;

    computePointDerivatives(points[i], local_gradient, local_hessian);

    // Critical section for global accumulation
    #pragma omp critical
    {
        gradient += local_gradient;
        hessian += local_hessian;
    }
}
#+end_src

#+begin_TIP
*Optimization*: Using thread-local accumulators with reduction eliminates critical section overhead. Each thread sums locally, then a final reduction combines results.
#+end_TIP

** Memory Access Patterns

For cache efficiency:
- Points stored contiguously in memory
- Voxel data (mean, icov) stored in arrays
- KD-tree queries access voxels in spatial locality

** Precomputation

| What | When Computed | Benefit |
|------+---------------+--------|
| Inverse covariance | Map load | Avoid per-point matrix inversion |
| Angular derivatives | Per iteration | Reuse across all points |
| KD-tree | Map load | Fast spatial queries |

* ROS Integration

** Subscriptions

| Topic | Type | Purpose |
|-------+------+---------|
| =/ekf_pose_with_covariance= | PoseWithCovarianceStamped | Initial guess from EKF |
| =/points_raw= | PointCloud2 | LiDAR scan |
| =/regularization_pose= | PoseWithCovarianceStamped | GNSS for regularization |

** Publications

| Topic                       | Type                      | Purpose                    |
|-----------------------------+---------------------------+----------------------------|
| =/ndt_pose=                 | PoseStamped               | Estimated pose             |
| =/ndt_pose_with_covariance= | PoseWithCovarianceStamped | Pose with uncertainty      |
| =/tf=                       | TFMessage                 | map -> base_link transform |
| =/diagnostics=              | DiagnosticArray           | Score, iterations, timing  |

** Processing Flow

#+begin_src mermaid
sequenceDiagram
    participant EKF
    participant NDT
    participant MapServer

    EKF->>NDT: Initial pose guess
    Note over NDT: Wait for scan
    LiDAR->>NDT: Point cloud
    NDT->>MapServer: Request map (if needed)
    MapServer-->>NDT: Map tiles
    Note over NDT: NDT alignment
    NDT->>EKF: Aligned pose
    NDT->>TF: Broadcast transform
#+end_src

* Accuracy Analysis: What Affects Alignment Quality?

Understanding which steps affect accuracy is critical for tuning and debugging NDT.

** Accuracy Impact Summary

| Step | Accuracy Impact | Why It Matters |
|------+-----------------|----------------|
| Voxel resolution | *Critical* | Determines spatial granularity of map representation |
| Covariance regularization | *High* | Prevents degenerate voxels, affects gradient smoothness |
| Search method (KDTREE vs DIRECT) | *High* | KDTREE provides smoother gradients, better convergence |
| Number of voxels per point | *High* | More voxels = smoother gradient = better convergence |
| Initial pose quality | *High* | Poor initialization can lead to local minima |
| Convergence threshold | *Medium* | Too loose = inaccurate; too tight = slow/non-convergent |
| Hessian regularization | *Medium* | Affects step direction in ill-conditioned regions |
| Line search | *Low-Medium* | Disabled by default; helps in difficult cases |
| Outlier ratio | *Low* | Controls Gaussian shape; 0.55 works well |

** Voxel Resolution (Critical)

The voxel resolution (default: 2.0m) is the most impactful parameter:

| Resolution | Pros | Cons | Use Case |
|------------+------+------+----------|
| 0.5-1.0m | High precision | Sensitive to noise, slow | Indoor, structured |
| 1.0-2.0m | Good balance | Standard choice | Urban driving |
| 2.0-4.0m | Fast, robust | Lower precision | Highway, open areas |

#+begin_IMPORTANT
*Rule of thumb*: Resolution should be 2-4x the expected position uncertainty. For autonomous driving with good IMU/odometry, 2.0m works well.
#+end_IMPORTANT

** Voxel Statistics Quality

Each voxel needs sufficient points for a reliable Gaussian estimate:

$$\text{min\_points\_per\_voxel} \geq 6$$

Sparse voxels (fewer points) produce unreliable covariances:

#+begin_src cpp
// Autoware default
if (voxel.nr_points < min_points_per_voxel_) {
    // Skip this voxel - not enough data for reliable statistics
    continue;
}
#+end_src

** Multi-Voxel Correspondence

The number of voxels found per point directly affects gradient quality:

| Voxels/Point | Gradient Quality | Convergence |
|--------------+------------------+-------------|
| < 1.0 | Poor (many points unmatched) | Unreliable |
| 1.0 - 2.0 | Acceptable | Usually works |
| 2.0 - 4.0 | Good (smooth gradient) | Reliable |
| > 4.0 | Excellent but slower | Best |

#+begin_NOTE
*Diagnostic*: Monitor the "voxels per point" metric. If consistently < 1.5, the map may have coverage gaps or resolution mismatch.
#+end_NOTE

** Initial Pose Quality

NDT is a local optimizer - it finds the nearest local minimum:

#+begin_src mermaid
graph LR
    A[Good Init] --> B[Global Minimum]
    C[Poor Init] --> D[Local Minimum]
    E[Very Poor Init] --> F[Divergence]
#+end_src

| Initial Error | Typical Outcome |
|---------------+-----------------|
| < 0.5m, < 5° | Converges to global minimum |
| 0.5-2.0m, 5-15° | Usually converges, may need more iterations |
| > 2.0m, > 15° | Risk of local minimum or divergence |

** Covariance Regularization

Degenerate covariances (e.g., planar surfaces) cause numerical issues:

#+begin_src cpp
// Eigenvalue clamping prevents singularity
for (int i = 0; i < 3; i++) {
    eigenvalues[i] = max(eigenvalues[i],
                         0.01 * eigenvalues.maxCoeff());
}
#+end_src

Without regularization:
- Matrix inversion fails for planar voxels
- Gradients become unstable
- Optimization may diverge

** Convergence Threshold Tuning

| Parameter | Default | Effect of Increase | Effect of Decrease |
|-----------+---------+--------------------+--------------------|
| =transformation_epsilon= | 0.01 | Faster but less accurate | More accurate but slower |
| =max_iterations= | 30 | More time for convergence | May stop early |
| =step_size= | 0.1 | Larger steps, faster | Smaller steps, more stable |

* GPU/Parallel Optimization Opportunities

This section analyzes which NDT components benefit from GPU acceleration and how the CUDA implementation achieves its speedups.

#+begin_NOTE
*Visual Reference*: See =docs/diagrams/ndt-dataflow.typ= Figure 2 (CPU vs GPU Pipeline) and Figure 4 (Derivative Computation) for visual comparisons.
#+end_NOTE

** Optimization Opportunity Matrix

| Step | Parallelizable? | GPU Benefit | Batching Benefit | CUDA Implementation |
|------+-----------------+-------------+------------------+---------------------|
| Voxel grid build | *Yes* (embarrassingly parallel) | *High* | Medium | CubeCL + CUB RadixSort |
| Point transformation | *Yes* (per-point) | *High* | High | Fused GPU kernel |
| Voxel search | *Yes* (per-point) | *High* | High | GPU spatial hash table |
| Score computation | *Yes* (per-point) | *High* | High | Fused GPU kernel |
| Gradient computation | *Yes* (per-point, reduce) | *High* | High | GPU kernel + CUB SegmentedReduce |
| Hessian computation | *Yes* (per-point, reduce) | *High* | High | GPU kernel + CUB SegmentedReduce |
| Angular derivatives | No (6 trig calls) | None | None | GPU-side (single-thread) |
| Newton solve | No (6×6 system) | Low | Medium | In-kernel Jacobi SVD |
| Convergence check | No | None | None | GPU-side |

** How CUDA Achieves 22% Speedup

The CUDA implementation achieves 6.10ms vs Autoware's 7.79ms through several key optimizations:

*** 1. Zero-Copy Iteration Pipeline

The critical insight: minimize CPU↔GPU transfers by keeping all iteration data on GPU.

#+begin_src
CPU Pipeline (Autoware):           GPU Pipeline (CUDA):
┌────────────────────────┐         ┌────────────────────────┐
│ Per Iteration:         │         │ One-Time Upload:       │
│  - Transform (CPU)     │         │  - Points: 64 bytes    │
│  - KD-tree search      │         │  - Voxels: V × 48B     │
│  - Accumulate grad/hess│         ├────────────────────────┤
│  - Critical section    │         │ Per Iteration (GPU):   │
│                        │         │  - Transform kernel    │
│ OpenMP threads merge   │         │  - Search kernel       │
│ via critical section   │         │  - Derivative kernel   │
└────────────────────────┘         │  - CUB reduce          │
                                   │  - Newton solve        │
Transfer: 0 bytes                  │  (No CPU roundtrip!)   │
Bottleneck: Critical section       └────────────────────────┘

                                   Download only at end:
                                   - Result: 172 bytes
#+end_src

| Metric | Autoware | CUDA | Difference |
|--------+----------+------+------------|
| Per-iter CPU↔GPU transfer | 0 (all CPU) | 0 (all GPU) | Same |
| Per-alignment upload | N/A | ~3 KB | One-time cost |
| Critical section overhead | ~0.3ms/iter | 0 | Eliminated |
| Sync points per iteration | Many (OpenMP) | 1 (kernel end) | Minimal |

*** 2. Spatial Hash Table vs KD-tree

Autoware uses KD-tree with $O(\log V)$ per-point queries. CUDA uses a GPU-friendly spatial hash:

#+begin_src
KD-tree (Autoware):                Spatial Hash (CUDA):
┌─────────────────────────┐        ┌─────────────────────────┐
│ For each point:         │        │ For each point:         │
│  1. Traverse tree       │        │  1. Hash(x,y,z) → idx   │
│  2. Radius search       │        │  2. Check 27 neighbors  │
│  3. Return nearby voxels│        │  3. Distance filter     │
│                         │        │                         │
│ Complexity: O(log V)    │        │ Complexity: O(1)        │
│ Cache: Poor (pointer    │        │ Cache: Good (contiguous │
│         chasing)        │        │         memory)         │
└─────────────────────────┘        └─────────────────────────┘
#+end_src

| Operation | KD-tree (CPU) | Spatial Hash (GPU) | Notes |
|-----------+---------------+--------------------+-------|
| Build time | ~10ms | ~2ms | Hash is simpler |
| Query time | ~300μs (N pts) | ~100μs (N pts) | Parallel queries |
| Memory pattern | Random | Coalesced | GPU-friendly |

*** 3. Column-Major Derivative Output

The derivative kernels output in column-major format for efficient reduction:

#+begin_src
Row-Major (Natural but slow):      Column-Major (Efficient reduction):
┌────────────────────────┐         ┌────────────────────────┐
│ Point 0: g0 g1 g2 g3 g4 g5│      │ All g0: P0.g0 P1.g0 ... Pn.g0│
│ Point 1: g0 g1 g2 g3 g4 g5│      │ All g1: P0.g1 P1.g1 ... Pn.g1│
│ Point 2: g0 g1 g2 g3 g4 g5│      │ ...                          │
│ ...                       │      │ All g5: P0.g5 P1.g5 ... Pn.g5│
└────────────────────────┘         └────────────────────────┘

Reduce: Gather scatter (slow)      Reduce: Contiguous sum (fast)
#+end_src

CUB DeviceSegmentedReduce then sums each column in a single pass:

#+begin_src cpp
// 43 segments: 1 score + 6 gradient + 36 Hessian
// Each segment is N contiguous floats
cub::DeviceSegmentedReduce::Sum(
    d_temp, temp_bytes,
    d_per_point_values,   // [score0..scoreN, grad0_0..grad0_N, ...]
    d_reduced_values,     // [sum_score, sum_grad0, ..., sum_hess35]
    43,                   // Number of segments
    d_segment_offsets,    // [0, N, 2N, ..., 43N]
    stream
);
#+end_src

*** 4. In-Kernel Newton Solve

Instead of transferring Hessian/gradient to CPU for solving, we solve directly on GPU:

#+begin_src
Autoware (CPU solve):              CUDA (GPU solve):
┌─────────────────────────┐        ┌─────────────────────────┐
│ 1. Download H (36 floats)│       │ 1. Jacobi SVD in kernel │
│ 2. Download g (6 floats) │       │    (6×6 is tiny)        │
│ 3. Eigen SVD on CPU     │        │ 2. Compute Δp on GPU    │
│ 4. Upload Δp (6 floats) │        │ 3. Update pose on GPU   │
│                         │        │ 4. No CPU roundtrip     │
│ Latency: ~100μs         │        │                         │
└─────────────────────────┘        │ Latency: ~10μs          │
                                   └─────────────────────────┘
#+end_src

The 6×6 Jacobi SVD is implemented in a single GPU thread (no parallelism needed for such a small matrix).

** Voxel Grid Construction (GPU)

*Highly parallelizable* - Each point is processed independently.

#+begin_src
GPU Voxel Grid Pipeline:
┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐
│ Points   │→ │ Morton   │→ │ Radix    │→ │ Segment  │→ │ Compute  │
│ N × 3    │  │ Encode   │  │ Sort     │  │ Detect   │  │ Stats    │
└──────────┘  └──────────┘  └──────────┘  └──────────┘  └──────────┘
              CubeCL kernel  CUB library  CUB library   CubeCL kernel

Output: V voxels, each with mean (3), inverse_cov (9), point_count (1)
#+end_src

| Operation | CPU Time | GPU Time | Speedup |
|-----------+----------+----------+---------|
| Morton codes | ~50ms | ~1ms | 50× |
| Radix sort | ~100ms | ~2ms | 50× |
| Segment detect | ~20ms | ~0.5ms | 40× |
| Statistics | ~50ms | ~5ms | 10× |
| *Total* | ~220ms | ~8.5ms | ~26× |

*Key insight*: Voxel grid is built once per map load, so GPU speedup amortizes over thousands of alignments.

** Derivative Computation (Main Bottleneck)

This is where GPU acceleration provides the most benefit:

*** CPU Approach (Autoware/OpenMP)

#+begin_src cpp
// OpenMP parallelizes over points, but has critical section
#pragma omp parallel for schedule(guided, 8)
for (int i = 0; i < N; i++) {
    Eigen::Matrix<double, 6, 1> local_grad = Eigen::Matrix<double, 6, 1>::Zero();
    Eigen::Matrix<double, 6, 6> local_hess = Eigen::Matrix<double, 6, 6>::Zero();

    for (int j : kdtree.radiusSearch(points[i], radius)) {
        computePointDerivatives(points[i], voxels[j], local_grad, local_hess);
    }

    // BOTTLENECK: Critical section for accumulation
    #pragma omp critical
    {
        gradient += local_grad;
        hessian += local_hess;
    }
}
#+end_src

*Bottleneck*: The critical section serializes thread accumulation, limiting speedup.

*** GPU Approach (CubeCL)

#+begin_src rust
// CubeCL kernel: One thread per point, no critical section
#[cube(launch)]
fn compute_derivatives_kernel(
    transformed_points: &Tensor<f32>,   // N × 3
    voxel_means: &Tensor<f32>,          // V × 3
    voxel_inv_covs: &Tensor<f32>,       // V × 9
    hash_table: &Tensor<u32>,           // Spatial hash
    #[output] scores: &mut Tensor<f32>, // N (column 0)
    #[output] grads: &mut Tensor<f32>,  // N × 6 (columns 1-6)
    #[output] hessians: &mut Tensor<f32>, // N × 21 (columns 7-27)
) {
    let i = ABSOLUTE_POS;
    let point = load_point(transformed_points, i);

    let mut local_score = 0.0f32;
    let mut local_grad = [0.0f32; 6];
    let mut local_hess = [0.0f32; 21];

    // Each thread checks its neighborhood independently
    for voxel_idx in spatial_hash_neighbors(point, hash_table) {
        let voxel = load_voxel(voxel_means, voxel_inv_covs, voxel_idx);
        accumulate_derivatives(point, voxel, &mut local_score,
                               &mut local_grad, &mut local_hess);
    }

    // Write to column-major output (no contention!)
    store_column_major(scores, grads, hessians, i,
                       local_score, local_grad, local_hess);
}
// CUB reduces columns in parallel → final 43 values
#+end_src

*No critical section*: Each thread writes to its own output location, then CUB reduces.

| Metric | CPU (OpenMP 8 threads) | GPU (RTX 4070) | Speedup |
|--------+------------------------+----------------+---------|
| Points | 750 | 750 | - |
| Voxels/point | ~2.4 | ~2.4 | - |
| Critical section time | ~0.3ms/iter | 0ms | Eliminated |
| Reduction time | ~0.1ms | ~0.05ms | 2× |
| *Time/iteration* | ~2.0ms | ~0.5ms | *4×* |

** Reduction Strategy Comparison

| Strategy | Transfer Size | Latency | Throughput | Used By |
|----------+---------------+---------+------------+---------|
| CPU reduction | 0 (local) | ~100μs | Good | OpenMP |
| GPU→CPU reduction | N×43 floats | ~200μs | Poor | Legacy |
| GPU atomic add | 43 floats | ~50μs | Contention | Not used |
| *GPU segmented reduce* | 43 floats | ~30μs | *Best* | CUDA impl |

** Newton Solve Comparison

| Method | Time | Transfer | Used By |
|--------+------+----------+---------|
| CPU Eigen SVD | ~50μs | H(36)+g(6)→CPU, Δp(6)→GPU | Autoware |
| CPU Eigen LLT | ~10μs | Same | Alternative |
| *GPU Jacobi SVD* | ~20μs | *None* | CUDA impl |

The GPU Jacobi SVD is slightly slower in isolation, but eliminates transfer latency:

| Scenario | CPU Solve | GPU Solve |
|----------+-----------+-----------|
| Solve time | 50μs | 20μs |
| Transfer time | 100μs | 0μs |
| *Total* | *150μs* | *20μs* |

** Batching Opportunities

*** Initial Pose Estimation (Monte Carlo + TPE)

The initial pose estimator evaluates many candidate poses in parallel:

#+begin_src
Sequential (Autoware):             Batched (CUDA):
┌─────────────────────────┐        ┌─────────────────────────┐
│ For each particle:      │        │ Upload all particles    │
│  1. Set pose            │        │ (100-200 poses)         │
│  2. Full NDT alignment  │        │                         │
│  3. Record score        │        │ Single batched kernel:  │
│                         │        │  - All transforms       │
│ Time: N × 3-5ms         │        │  - All searches         │
│      = 300-500ms        │        │  - All scores           │
└─────────────────────────┘        │                         │
                                   │ Time: ~20-50ms          │
                                   └─────────────────────────┘
#+end_src

| N (particles) | Sequential | Batched GPU | Speedup |
|---------------+------------+-------------+---------|
| 100 | 300ms | 25ms | 12× |
| 200 | 500ms | 45ms | 11× |

*** Multi-NDT Covariance Estimation

Covariance estimation perturbs the initial pose and runs multiple alignments:

| Grid Size | Alignments | Sequential | Batched GPU | Speedup |
|-----------+------------+------------+-------------+---------|
| 3×3 | 9 | 27ms | 5ms | 5.4× |
| 5×5 | 25 | 75ms | 12ms | 6.3× |

** GPU Pipeline Architecture Summary

#+begin_src
┌───────────────────────────────────────────────────────────────────┐
│                    Per-Alignment Setup (Once)                      │
├───────────────────────────────────────────────────────────────────┤
│  CPU → GPU:                                                        │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐             │
│  │ Source Points│  │ Voxel Means  │  │ Voxel InvCov │             │
│  │ N × 3 × 4B   │  │ V × 3 × 4B   │  │ V × 9 × 4B   │             │
│  │ (~3 KB)      │  │ (~36 KB)     │  │ (~108 KB)    │             │
│  └──────────────┘  └──────────────┘  └──────────────┘             │
│                                                                    │
│  Build: Spatial hash table from voxel positions                    │
└───────────────────────────────────────────────────────────────────┘
                              ↓
┌───────────────────────────────────────────────────────────────────┐
│                   Per-Iteration (All GPU, No Transfer)             │
├───────────────────────────────────────────────────────────────────┤
│  ┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐       │
│  │Transform │ → │ Search   │ → │Derivative│ → │   CUB    │       │
│  │ Points   │   │ Voxels   │   │ Compute  │   │  Reduce  │       │
│  └──────────┘   └──────────┘   └──────────┘   └──────────┘       │
│       ↑                                              ↓            │
│       │         ┌──────────┐   ┌──────────┐         │            │
│       └─────────│  Update  │ ← │  Newton  │ ←───────┘            │
│                 │   Pose   │   │   Solve  │                      │
│                 └──────────┘   └──────────┘                      │
│                       │                                           │
│                       ↓ Converged?                                │
│                       No → Loop back                              │
│                       Yes ↓                                       │
└───────────────────────────────────────────────────────────────────┘
                              ↓
┌───────────────────────────────────────────────────────────────────┐
│                        Download Result                             │
├───────────────────────────────────────────────────────────────────┤
│  GPU → CPU:                                                        │
│  ┌──────────────────────────────────────────────┐                 │
│  │ Final Pose (6), Score (1), Iterations (1),   │                 │
│  │ Hessian (36), Converged (1)                  │                 │
│  │ Total: 172 bytes                             │                 │
│  └──────────────────────────────────────────────┘                 │
└───────────────────────────────────────────────────────────────────┘
#+end_src

* Current Performance Statistics

Real-world profiling data from AutoSDV rosbag with Velodyne VLP-32C LiDAR.

** Test Environment

| Parameter | Value |
|-----------+-------|
| Date | 2026-01-19 |
| GPU | NVIDIA RTX 4070 |
| Dataset | AutoSDV rosbag (Velodyne VLP-32C) |
| Map | sample-map-rosbag (point cloud) |
| Scan points | ~700-900 per frame (downsampled) |
| Voxel resolution | 2.0m |

** Execution Time Comparison

| Metric | Autoware (OpenMP) | CUDA GPU | Ratio |
|--------+-------------------+----------+-------|
| *Mean* | *7.79 ms* | *6.10 ms* | *1.28× faster* |
| Median | 7.64 ms | 6.03 ms | 1.27× faster |
| Stdev | 4.03 ms | 1.37 ms | Lower variance |
| Min | 1.89 ms | 3.31 ms | - |
| Max | 30.62 ms | 15.85 ms | 1.93× faster |
| P95 | 13.28 ms | 7.92 ms | 1.68× faster |
| P99 | 21.77 ms | 11.88 ms | 1.83× faster |

#+begin_SUCCESS
*CUDA is now faster than Autoware!* The GPU implementation achieves 22% lower mean execution time with significantly more consistent performance (lower variance).
#+end_SUCCESS

** Convergence Statistics

| Metric | Autoware | CUDA |
|--------+----------+------|
| Convergence rate | 100% | 100% |
| Mean iterations | 3.0 | 3.1 |
| Median iterations | 3 | 3 |
| Max iterations | 5 | 6 |
| Hit max iterations | 0% | 0% |

#+begin_NOTE
Both implementations achieve 100% convergence with similar iteration counts, indicating the CUDA implementation now matches Autoware's optimization behavior.
#+end_NOTE

** NVTL Score Comparison

| Metric | Autoware | CUDA | Notes |
|--------+----------+------+-------|
| Mean NVTL | 3.05 | 2.30 | 75% of Autoware |
| Stdev | 0.51 | 0.68 | Slightly higher variance |
| Total entries | 1340 | 281 | Different alignment counts |

The NVTL gap (75%) remains an area for investigation. Lower NVTL may indicate different voxel search strategies or scoring calculations.

** Timing Breakdown (Per Iteration)

| Component | Autoware (CPU) | CUDA (GPU) | Notes |
|-----------+----------------+------------+-------|
| Point transformation | ~0.05ms | <0.01ms | GPU excels |
| Voxel search | ~0.3ms | ~0.1ms | GPU spatial hash |
| Derivative computation | ~1.5ms | ~0.3ms | GPU kernels + CUB reduce |
| Newton solve | ~0.05ms | ~0.02ms | In-kernel Jacobi SVD |
| *Per-iteration total* | ~2.0ms | ~0.5ms | 4× faster |

#+begin_IMPORTANT
*Key insight*: With matching convergence rates, the GPU's 4× per-iteration speedup translates to overall 22% faster total execution time. The overhead comes from one-time upload costs (~2ms) that amortize over the alignment.
#+end_IMPORTANT

** Execution Time Distribution

#+begin_src
Autoware:                     CUDA GPU:
├── <5ms:   47%              ├── <5ms:   16%
├── 5-10ms: 35%              ├── 5-10ms: 78%
├── 10-15ms: 11%             ├── 10-15ms: 5%
└── >15ms:   7%              └── >15ms:  1%
#+end_src

CUDA shows a tighter distribution centered around 5-7ms, while Autoware has a longer tail. This makes CUDA more predictable for real-time systems.

** GPU Memory Transfer Analysis

Per-alignment transfer overhead (optimized pipeline):

| Direction | Data | Size | When |
|-----------+------+------+------|
| CPU→GPU | Pose (initial) | 64 bytes | Once per alignment |
| CPU→GPU | Source points | ~3 KB (750 × 4B) | Once per alignment |
| GPU→CPU | Result | 172 bytes | Once per alignment |
| *Total* | | ~3.2 KB | Per alignment |

The zero-copy pipeline eliminates per-iteration transfers:

| Metric | Old Pipeline | Zero-Copy Pipeline |
|--------+--------------+--------------------|
| Per-iter transfer | ~650 KB | 0 bytes |
| Per-alignment transfer | 6.5 MB (10 iter) | 3.2 KB |
| Transfer time | ~2ms/iter | ~10μs total |

* Summary

** Key Takeaways

1. *NDT models the map as Gaussians* - Smooth, differentiable objective function
2. *Newton optimization* - Fast convergence with proper initialization
3. *Derivative computation is the bottleneck* - $O(N \times V_{avg})$ per iteration, but highly parallelizable
4. *GPU eliminates critical sections* - Column-major output + CUB reduction vs OpenMP critical sections
5. *Zero-copy pipeline is key* - Keep all iteration data on GPU, transfer only at start/end
6. *In-kernel Newton solve* - Avoids CPU↔GPU transfer latency for 6×6 system
7. *Spatial hash vs KD-tree* - GPU-friendly O(1) lookup with coalesced memory access

** Performance Summary (2026-01-19)

| Metric | Autoware (CPU) | CUDA (GPU) | Improvement |
|--------+----------------+------------+-------------|
| Mean execution time | 7.79 ms | 6.10 ms | *22% faster* |
| P95 execution time | 13.28 ms | 7.92 ms | *40% faster* |
| Per-iteration time | ~2.0 ms | ~0.5 ms | *4× faster* |
| Mean iterations | 3.0 | 3.1 | Parity |
| Convergence rate | 100% | 100% | Parity |
| NVTL score | 3.05 | 2.30 | 75% (gap remains) |

** Typical Performance

| Metric                 | Autoware | CUDA GPU |
|------------------------+----------+----------|
| Points per scan        | 500-2000 | 500-2000 |
| Voxels per point       |      2-4 |      2-4 |
| Iterations to converge |      3-5 |      3-5 |
| Time per alignment     |   5-10ms |   4-8ms |

** Further Reading

- [[https://www.mrpt.org/downloads/dox/tutorial_ndt_3d.pdf][Magnusson 2009 PhD Thesis]] - Original NDT algorithm
- [[https://github.com/autowarefoundation/autoware_core][Autoware Core]] - Reference implementation
- [[https://pointclouds.org/documentation/classpcl_1_1_normal_distributions_transform.html][PCL NDT Documentation]] - PCL implementation details

* Appendix: Code References

** Autoware Files

| File                                | Description                         |
|-------------------------------------+-------------------------------------|
| =ndt_scan_matcher_core.cpp=         | ROS node, subscriptions, publishers |
| =multigrid_ndt_omp_impl.hpp=        | Core NDT algorithm                  |
| =multi_voxel_grid_covariance_omp.h= | Voxel grid data structure           |
| =map_update_module.hpp=             | Dynamic map loading                 |
| =hyper_parameters.hpp=              | Configuration parameters            |

** Key Functions

| Function                    | Location                       | Purpose                      |
|-----------------------------+--------------------------------+------------------------------|
| =computeTransformation()=   | multigrid_ndt_omp_impl.hpp:247 | Main optimization loop       |
| =computeDerivatives()=      | multigrid_ndt_omp_impl.hpp:418 | Gradient/Hessian computation |
| =computeAngleDerivatives()= | multigrid_ndt_omp_impl.hpp:576 | Precompute angular terms     |
| =computeStepLengthMT()=     | multigrid_ndt_omp_impl.hpp:971 | More-Thuente line search     |
| =updateDerivatives()=       | multigrid_ndt_omp_impl.hpp:702 | Per-point accumulation       |
